{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module 2 - Preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michnic120/Krzych-projects/blob/master/Module_2_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "e5oyiOADtpDA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Environment preparation - fetching dataset and library import"
      ]
    },
    {
      "metadata": {
        "id": "wflsY2wvtZ1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from scipy import misc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cz2JJbMRHmKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "90978964-f449-4345-d2aa-d34051955998"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NpwZ8qNbxGw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5f2d32c-844b-4a98-e6fc-b2d84488d2b4"
      },
      "cell_type": "code",
      "source": [
        "! date && unzip -q /content/drive/'My Drive'/celeb_dataset.zip -d /content/  && date #unzip dataset into local machine"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov 14 18:15:48 UTC 2018\n",
            "Wed Nov 14 18:19:36 UTC 2018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rJi0ivw_BmGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8d8fba8d-38ca-4a26-c138-f48fd36f5017"
      },
      "cell_type": "code",
      "source": [
        "#create a directory for preprocessed TFRecord files\n",
        "!ls /content/\n",
        "!mkdir /content/preprocessed/\n",
        "!ls /content/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "celeb  drive  sample_data\n",
            "celeb  drive  preprocessed  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTz-2mYx4fua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def peek_file(file_path, n_lines):\n",
        "  \"\"\"\n",
        "  helper function to peek first n_lines of the file\n",
        "  \"\"\"\n",
        "  try:\n",
        "    n_lines = int(n_lines)\n",
        "    assert(n_lines > 0)\n",
        "  except ValueError:\n",
        "    print(\"Number of lines argument must be integer-interpretable\")\n",
        "  except AssertionError:\n",
        "    print(\"Number of lines must be positive\")\n",
        "    \n",
        "  with open(file_path) as file:\n",
        "    for line in range(n_lines):\n",
        "      print(file.readline(), end=\"\")\n",
        "  return\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HU0WLUEnxMXM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ]
    },
    {
      "metadata": {
        "id": "Y79GEERuxd6a",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# path to downloaded dataset (unzipped)\n",
        "DOWNLOADED_PATH = '/content/celeb' #@param {type:\"string\"}\n",
        "\n",
        "# path to preprocessed dataset (tf records)\n",
        "SAVED_DATASET = '/content/preprocessed/' #@param {type:\"string\"}\n",
        "\n",
        "TRAIN_FILENAME = 'train.tfrecords' #@param {type:\"string\"}\n",
        "VAL_FILENAME = 'val.tfrecords' #@param {type:\"string\"}\n",
        "TEST_FILENAME = 'test.tfrecords' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# tensorflow tf records dataset settings\n",
        "DECODE_PARALLEL_CALLS = 103 #@param {type:\"slider\", min:20, max:400, step:1}\n",
        "SHUFFLE_BUFFER_SIZE = 100 #@param {type:\"slider\", min:20, max:400, step:1}\n",
        "PREFETCH_BUFFER_SIZE = 100 #@param {type:\"slider\", min:20, max:400, step:1}\n",
        "\n",
        "BATCH_SIZE = 37 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjbplYlPeGSV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ANNO_PATH = os.path.join(DOWNLOADED_PATH, 'Anno',  'list_attr_celeba.txt') #file that indicates to which classes an image belongs to \n",
        "IMG_PATH = os.path.join(DOWNLOADED_PATH, 'Img') #path to images directory\n",
        "EVAL_PATH = os.path.join(DOWNLOADED_PATH, 'Eval', 'list_eval_partition.txt') #file that indicates how to split the dataset into training, validation and testing sets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h7Ok7Y2G7jyf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Decoding TFRecords"
      ]
    },
    {
      "metadata": {
        "id": "z7vBYOaz7jMK",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dataset_wrapper(session, dataset):\n",
        "    \"\"\"\n",
        "    Wraps TensorFlow dataset into generator.\n",
        "    :param session:\n",
        "    :param dataset: tf.data.Dataset object\n",
        "    \"\"\"\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "    while True:\n",
        "        try:\n",
        "            data = session.run(next_element)\n",
        "            yield data\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "            \n",
        "def _decode_record(record):\n",
        "    \"\"\"\n",
        "    Decodes record from bytes to arrays.\n",
        "    \"\"\"\n",
        "    features_dict = {\n",
        "        'image': tf.FixedLenFeature((), tf.string),\n",
        "        'tags': tf.FixedLenFeature((), tf.string),\n",
        "    }\n",
        "\n",
        "    features = tf.parse_single_example(record, features=features_dict)\n",
        "    #data had been written as uint8 to save up space...\n",
        "    image = tf.decode_raw(features['image'], tf.uint8)\n",
        "    image = tf.reshape(image, shape=(218, 178, 3))\n",
        "    #.. but we need more precison on calculation\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255.0 #normalize\n",
        "    tags = tf.decode_raw(features['tags'], tf.uint8)\n",
        "\n",
        "    return {\n",
        "        'image': image,\n",
        "        'tags': tags\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-lGw92675t6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TASK 3\n",
        "def make_dataset(dataset_path, batch_size=128, shuffle=False, epochs=1, count_limit=None):\n",
        "    \"\"\"\n",
        "    Creates dataset pipeline. Use https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset\n",
        "    :param count_limit:\n",
        "    :return: tf.data.TFRecordDataset object\n",
        "    \"\"\"\n",
        "    dataset = dataset.prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4VU1E-b1Iwc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Writting to TFRecords"
      ]
    },
    {
      "metadata": {
        "id": "KTj0jMibE8Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "peek_file(EVAL_PATH, 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cf1hLkunFTWt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TASK 1\n",
        "\n",
        "def _load_splits():\n",
        "    \"\"\"\n",
        "    Load split for train/val/test dataset.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4b8JV19lFM2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "peek_file(ANNO_PATH, 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugqH806c1wS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TASK 2\n",
        "\n",
        "def _load_tags():\n",
        "    \"\"\"\n",
        "    Load tags (classes) for images.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbGi50hx2B-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "    \"\"\"\n",
        "    Helper function for feature encoding.\n",
        "    :param value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "def _write_records(dataset_filename, image_filename_iterator, tags):\n",
        "    \"\"\"\n",
        "    Writes images and tags to file.\n",
        "    :param dataset_filename:\n",
        "    :param image_filename_iterator: iterable containing filenames\n",
        "    :param tags: dictionary containing pairs filename: tags\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    with tf.python_io.TFRecordWriter(dataset_filename) as writer:\n",
        "        for image_filename in tqdm(iterable=image_filename_iterator,\n",
        "                                   desc='writting {} dataset'.format(dataset_filename)):\n",
        "            tag = tags[image_filename]\n",
        "            image = misc.imread(os.path.join(IMG_PATH, image_filename.replace('.jpg', '.png')))\n",
        "\n",
        "            # store as uint8\n",
        "            image = image.astype(np.uint8)\n",
        "            feature = {\n",
        "                'image': _bytes_feature([image.tostring()]),\n",
        "                'tags': _bytes_feature([tag.tostring()]),\n",
        "            }\n",
        "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "            writer.write(example.SerializeToString())\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQKAPnsX1Tis",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _create_dataset(train_filename, val_filename, test_filename):\n",
        "    \"\"\"\n",
        "    Creates dataset in target location.\n",
        "    To be implemented by students\n",
        "    :param train_filename:\n",
        "    :param val_filename:\n",
        "    :param test_filename:\n",
        "    \"\"\"\n",
        "    splits = _load_splits()\n",
        "    tags = _load_tags()\n",
        "\n",
        "    _write_records(train_filename, splits['0'], tags)\n",
        "    _write_records(val_filename, splits['1'], tags)\n",
        "    _write_records(test_filename, splits['2'], tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4goFOy2c1ISl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def maybe_create_dataset():\n",
        "    \"\"\"\n",
        "    Function creates TensorFlow dataset if it does not exist.\n",
        "    :return: (train_filename, val_filename, test_filename)\n",
        "    \"\"\"\n",
        "    train_filename = os.path.join(SAVED_DATASET, TRAIN_FILENAME)\n",
        "    val_filename = os.path.join(SAVED_DATASET, VAL_FILENAME)\n",
        "    test_filename = os.path.join(SAVED_DATASET, TEST_FILENAME)\n",
        "\n",
        "    if not all([os.path.exists(filename)\n",
        "                for filename\n",
        "                in [train_filename, val_filename, test_filename]]):\n",
        "        _create_dataset(train_filename, val_filename, test_filename)\n",
        "    return train_filename, val_filename, test_filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NlCSDMylzd7d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Main pipeline"
      ]
    },
    {
      "metadata": {
        "id": "HWC-26Di0rRU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_filename, val_filename, test_filename = maybe_create_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXlvIrHW0sou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    train_set = make_dataset(\n",
        "        dataset_path=test_filename,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        epochs=5,\n",
        "        count_limit=COUNT_LIMIT,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sXLqqjvD01nv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:    \n",
        "    for data in tqdm(dataset_wrapper(session, train_set)):\n",
        "        break\n",
        "        \n",
        "\n",
        "    for data in tqdm(dataset_wrapper(session, train_set)):\n",
        "        plt.imshow(data['image'][0])\n",
        "        plt.show()\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}